## Escribir las reglas de análisis:

### 1.- Utilizar tu tabla de tokens
Antes de escribir las reglas de análisis, necesitas tener tu lista de los tokens 
que tu analizador léxico debe reconocer en el texto de entrada. Estos tokens pueden incluir palabras clave, 
identificadores, números, operadores, símbolos especiales, etc.

### Tabla de tokens

| Tipo                           | Token            | Lexema   | Función                             | Expresión Regular      |
| ------------------------------ | ---------------- | -------- | ----------------------------------- | ---------------------- |
| Identificador                  | IDENTIFIER       | abc123\_ | Identificador                       | [a-zA-Z\_][a-zA-Z0-9_] |
| Operadores matemáticos         | PLUS             | +        | Operador de suma                    | \\\+                   |
|                                | MINUS            | -        | Operador de resta                   | \\\-                   |
|                                | TIMES            | \*       | Operador de multiplicación          | \\\*                   |
|                                | DIVIDE           | /        | Operador de división                | /                      |
|                                | MODULO           | %        | Operador de módulo                  | %                      |
|                                | POWER            | \*\*     | Operador de potencia                | \*\*                   |
|                                | ASSIGN_OP        | :=       | Operador de asignación implícita    | :=                     |
|                                | TYPE_DECLARATION | :        | Operador de asignación explícita    | :                      |
| Operadores logicos             | COMPARISON       | =        | Operador de comparación             | =                      |
|                                | LESS_THAN        | <        | Operador menor que                  | <                      |
|                                | GREATER_THAN     | >        | Operador mayor que                  | >                      |
|                                | GREATER_EQUAL    | >=       | Operador mayor o igual que          | >=                     |
|                                | LESS_EQUAL       | <=       | Operador menor o igual que          | <=                     |
|                                | NOT_EQUAL        | !=       | Operador de desigualdad             | !=                     |
|                                | NOT              | !        | Operador de negación                | !                      |
|                                | AND              | &&       | Operador lógico AND                 | &&                     |
|                                | OR               | \|\|     | Operador lógico OR                  | \|\|                   |
| Inicio de comentario de bloque | COMMENT_START    | \/?      | Inicio de comentario                | \/\?                   |
| Fin de comentario de bloque    | COMMENT_END      | ?\/      | Fin de comentario                   | \?\/                   |
| Paréntesis                     | LEFT_PAREN       | (        | Paréntesis izquierdo                | \(                     |
|                                | RIGHT_PAREN      | )        | Paréntesis derecho                  | \)                     |
| Corchetes                      | LEFT_BRACKET     | [        | Corchete izquierdo                  | \[                     |
|                                | RIGHT_BRACKET    | ]        | Corchete derecho                    | \]                     |
| Llaves                         | LEFT_BRACE       | {        | Llave izquierda (llave de apertura) | \{                     |
|                                | RIGHT_BRACE      | }        | Llave derecha (llave de cierre)     | \}                     |
|                                | SEMICOLO         | ;        | Fin de instruccion                  | ;                      |
### Palabras reservadas

| Tipo                   | Token    | Lexema | Función                      | Expresión Regular |
| ---------------------- | -------- | ------ | ---------------------------- | ----------------- |
| Funcion                | FUNCTION | fun    | Define una función           | fun               |
|                        | RETURNS  | ->     | Indica un retorno            | ->                |
| Estructuras de control | IF       | if     | Estructura de control 'if'   | if                |
|                        | ELSE     | else   | Estructura de control 'else' | else              |
|                        | FOR      | for    | Bucle 'for'                  | for               |
|                        | IN       | in     | Operador de pertenencia      | in                |
|                        | WHILE    | while  | Bucle 'while'                | while             |

### Tipos de datos

| Tipos de datos | Token        | Lexema | Función                   | Expresión Regular |
| -------------- | ------------ | ------ | ------------------------- | ----------------- |
| Tipos          | TYPE_INTEGER | int    | Valores enteros           | int               |
|                | TYPE_STRING  | str    | Valores de texto          | str               |
|                | TYPE_FLOAT   | float  | Valores decimales simples | float             |
|                | TYPE_DOUBLE  | double | Valores decimales         | double            |
|                | TYPE_BOOL    | bool   | Valores boleanos          | bool              |

### Literales de tipos de datos

| Literales | Token  | Lexema      | Función                             | Expresión Regular |
| --------- | ------ | ----------- | ----------------------------------- | ----------------- |
|           | STRING | "any"       | Literal de texto                    | "[^\s\"]"         |
|           | INT    | 0-9         | Número literal                      | [0-9]+            |
|           | FLOAT  | 0-9.0-9f    | Literal número coma flotante simple | [0-9]+\.[0-9]+f   |
|           | DOUBLE | 0-9.0-9     | Literal número coma flotante doble  | [0-9]+\.[0-9]+    |
|           | BOOL   | true\|false | Literal de valor boleano            | (true\|false)     |

### 2.- Escribir las reglas de coincidencia:
Utilizando la sintaxis proporcionada por la herramienta o librería 
seleccionada, escribe las reglas de coincidencia que definan cómo se reconocen los tokens en el texto de entrada.
Estas reglas suelen estar escritas en forma de expresiones regulares o reglas de coincidencia de patrones.

#### Nuestras reglas de coincidencia:

#### Para operadores matemáticos
t_PLUS = r'\+'
t_MINUS = r'-'
t_TIMES = r'\*'
t_DIVIDE = r'/'
t_MODULO = r'%'

#### Para operadores de asignación y comparación
t_ASSIGN_OP = r':='
t_ASSIGN_OP_SHORT = r':'
t_COMPARISON = r'='

#### Para operadores de comparación
t_LESS_THAN = r'<'
t_GREATER_THAN = r'>'
t_GREATER_EQUAL = r'>='
t_LESS_EQUAL = r'<='
t_NOT_EQUAL = r'!='

#### Para operadores lógicos
t_NOT = r'!'
t_AND = r'&&'
t_OR = r'\|\|'

#### Para paréntesis, corchetes y llaves
t_LEFT_PAREN = r'\('
t_RIGHT_PAREN = r'\)'
t_LEFT_BRACKET = r'\['
t_RIGHT_BRACKET = r'\]'
t_LEFT_BRACE = r'\{'
t_RIGHT_BRACE = r'\}'

### 3.- Asociar acciones a las reglas:
Además de definir las reglas de coincidencia, también puedes asociar acciones a cada 
regla. Estas acciones se ejecutan cuando se reconoce un token según la regla correspondiente. Las acciones pueden 
incluir la asignación de un tipo de token, la recopilación de información adicional, la generación de mensajes de 
error, etc.

def t_RETURNS(t):
    r'returns'
    return t

def t_INTEGER(t):
    r'\d+'
    t.value = int(t.value)  # Convertir el valor del token a un entero
    return t

def t_STRING(t):
    r'\'[^\']*\''
    t.value = t.value[1:-1]  # Eliminar las comillas del principio y del final
    return t

def t_FUNCTION(t):
    r'fun'
    return t

def t_IF(t):
    r'if'
    return t

def t_ELSE(t):
    r'else'
    return t

def t_FOR(t):
    r'for'
    return t

def t_WHILE(t):
    r'while'
    return t

def t_IDENTIFIER(t):
    r'[a-zA-Z_][a-zA-Z0-9_]*'
    return t

### 4.- Manejo de casos especiales:
Considera cómo manejar los casos especiales o ambigüedades en las reglas de análisis. 
Por ejemplo, si un mismo patrón puede corresponder a múltiples tokens, debes definir reglas que especifiquen cómo
resolver estas ambigüedades.

def t_COMMENT(t):
    r'\?.*'
    pass

def t_SPACE(t):
    r'\t+'
    pass

def t_NEWLINE(t):
    r'\n+'
    t.lexer.lineno += len(t.value)

def t_error(t):
    global resultado_lexema
    estado = "** El token no es válido en la línea {:4} Valor {:16} Posición {:4}".format(str(t.lineno), str(t.value), str(t.lexpos))
    resultado_lexema.append(estado)
    t.lexer.skip(1)


### 5.- Pruebas de las reglas:
Después de escribir las reglas de análisis, pruébalas utilizando una variedad de ejemplos 
de texto de entrada para asegurarte de que funcionen correctamente. Ajusta las reglas según sea necesario para 
corregir cualquier error o comportamiento inesperado que encuentres durante las pruebas.

### 6.- Optimización (opcional):
Si es necesario, puedes optimizar las reglas de análisis para mejorar el rendimiento de 
tu analizador léxico. Esto puede incluir la reorganización de las reglas para minimizar la cantidad de comparaciones 
necesarias o el uso de técnicas avanzadas de coincidencia de patrones.
