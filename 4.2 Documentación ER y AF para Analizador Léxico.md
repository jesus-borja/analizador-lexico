## Escribir las reglas de análisis:

Utilizar tu tabla de tokens: Antes de escribir las reglas de análisis, necesitas tener tu lista de los tokens 
que tu analizador léxico debe reconocer en el texto de entrada. Estos tokens pueden incluir palabras clave, 
identificadores, números, operadores, símbolos especiales, etc.

Escribir las reglas de coincidencia: Utilizando la sintaxis proporcionada por la herramienta o librería 
seleccionada, escribe las reglas de coincidencia que definan cómo se reconocen los tokens en el texto de entrada.
Estas reglas suelen estar escritas en forma de expresiones regulares o reglas de coincidencia de patrones.

Asociar acciones a las reglas: Además de definir las reglas de coincidencia, también puedes asociar acciones a cada 
regla. Estas acciones se ejecutan cuando se reconoce un token según la regla correspondiente. Las acciones pueden 
incluir la asignación de un tipo de token, la recopilación de información adicional, la generación de mensajes de 
error, etc.

Manejo de casos especiales: Considera cómo manejar los casos especiales o ambigüedades en las reglas de análisis. 
Por ejemplo, si un mismo patrón puede corresponder a múltiples tokens, debes definir reglas que especifiquen cómo
resolver estas ambigüedades.

Pruebas de las reglas: Después de escribir las reglas de análisis, pruébalas utilizando una variedad de ejemplos 
de texto de entrada para asegurarte de que funcionen correctamente. Ajusta las reglas según sea necesario para 
corregir cualquier error o comportamiento inesperado que encuentres durante las pruebas.

Optimización (opcional): Si es necesario, puedes optimizar las reglas de análisis para mejorar el rendimiento de 
tu analizador léxico. Esto puede incluir la reorganización de las reglas para minimizar la cantidad de comparaciones 
necesarias o el uso de técnicas avanzadas de coincidencia de patrones.
